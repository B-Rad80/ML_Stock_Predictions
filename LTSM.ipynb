{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Brandon Roemer and Vincent Lou (did I spell your name right?)\n",
    "\n",
    "Initial model built from:\n",
    "    https://machinelearningmastery.com/time-series-prediction-lstm-recurrent-neural-networks-python-keras/\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "\n",
    "#import sklearn\n",
    "#import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Open.1</th>\n",
       "      <th>High.1</th>\n",
       "      <th>Low.1</th>\n",
       "      <th>Close.1</th>\n",
       "      <th>Volume.1</th>\n",
       "      <th>Open.2</th>\n",
       "      <th>High.2</th>\n",
       "      <th>Low.2</th>\n",
       "      <th>Close.2</th>\n",
       "      <th>Volume.2</th>\n",
       "      <th>Open.3</th>\n",
       "      <th>High.3</th>\n",
       "      <th>Low.3</th>\n",
       "      <th>Close.3</th>\n",
       "      <th>Volume.3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.207278</td>\n",
       "      <td>0.266271</td>\n",
       "      <td>0.207774</td>\n",
       "      <td>0.040335</td>\n",
       "      <td>0.317724</td>\n",
       "      <td>0.316066</td>\n",
       "      <td>0.314614</td>\n",
       "      <td>0.315107</td>\n",
       "      <td>0.014362</td>\n",
       "      <td>0.221744</td>\n",
       "      <td>0.221735</td>\n",
       "      <td>0.219592</td>\n",
       "      <td>0.218835</td>\n",
       "      <td>0.071630</td>\n",
       "      <td>0.121008</td>\n",
       "      <td>0.120398</td>\n",
       "      <td>0.120547</td>\n",
       "      <td>0.121613</td>\n",
       "      <td>0.265755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.205954</td>\n",
       "      <td>0.268285</td>\n",
       "      <td>0.211104</td>\n",
       "      <td>0.020598</td>\n",
       "      <td>0.313595</td>\n",
       "      <td>0.312520</td>\n",
       "      <td>0.313730</td>\n",
       "      <td>0.316131</td>\n",
       "      <td>0.005885</td>\n",
       "      <td>0.216649</td>\n",
       "      <td>0.221677</td>\n",
       "      <td>0.222476</td>\n",
       "      <td>0.225798</td>\n",
       "      <td>0.064605</td>\n",
       "      <td>0.119878</td>\n",
       "      <td>0.121420</td>\n",
       "      <td>0.124930</td>\n",
       "      <td>0.127285</td>\n",
       "      <td>0.215039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.204670</td>\n",
       "      <td>0.267314</td>\n",
       "      <td>0.208549</td>\n",
       "      <td>0.020888</td>\n",
       "      <td>0.310289</td>\n",
       "      <td>0.307719</td>\n",
       "      <td>0.308843</td>\n",
       "      <td>0.307302</td>\n",
       "      <td>0.008160</td>\n",
       "      <td>0.217424</td>\n",
       "      <td>0.217205</td>\n",
       "      <td>0.220296</td>\n",
       "      <td>0.218899</td>\n",
       "      <td>0.031678</td>\n",
       "      <td>0.124445</td>\n",
       "      <td>0.119637</td>\n",
       "      <td>0.127240</td>\n",
       "      <td>0.125837</td>\n",
       "      <td>0.218488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.205098</td>\n",
       "      <td>0.267961</td>\n",
       "      <td>0.209943</td>\n",
       "      <td>0.032848</td>\n",
       "      <td>0.304350</td>\n",
       "      <td>0.303431</td>\n",
       "      <td>0.307455</td>\n",
       "      <td>0.307065</td>\n",
       "      <td>0.016842</td>\n",
       "      <td>0.216899</td>\n",
       "      <td>0.217857</td>\n",
       "      <td>0.221881</td>\n",
       "      <td>0.220296</td>\n",
       "      <td>0.035793</td>\n",
       "      <td>0.124038</td>\n",
       "      <td>0.120821</td>\n",
       "      <td>0.128372</td>\n",
       "      <td>0.126066</td>\n",
       "      <td>0.164931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.205293</td>\n",
       "      <td>0.268213</td>\n",
       "      <td>0.209400</td>\n",
       "      <td>0.077209</td>\n",
       "      <td>0.305648</td>\n",
       "      <td>0.304895</td>\n",
       "      <td>0.307398</td>\n",
       "      <td>0.308051</td>\n",
       "      <td>0.003199</td>\n",
       "      <td>0.219603</td>\n",
       "      <td>0.218163</td>\n",
       "      <td>0.222712</td>\n",
       "      <td>0.221599</td>\n",
       "      <td>0.059641</td>\n",
       "      <td>0.124868</td>\n",
       "      <td>0.122011</td>\n",
       "      <td>0.128281</td>\n",
       "      <td>0.127560</td>\n",
       "      <td>0.189904</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       High       Low     Close    Volume    Open.1    High.1     Low.1  \\\n",
       "0  0.207278  0.266271  0.207774  0.040335  0.317724  0.316066  0.314614   \n",
       "1  0.205954  0.268285  0.211104  0.020598  0.313595  0.312520  0.313730   \n",
       "2  0.204670  0.267314  0.208549  0.020888  0.310289  0.307719  0.308843   \n",
       "3  0.205098  0.267961  0.209943  0.032848  0.304350  0.303431  0.307455   \n",
       "4  0.205293  0.268213  0.209400  0.077209  0.305648  0.304895  0.307398   \n",
       "\n",
       "    Close.1  Volume.1    Open.2    High.2     Low.2   Close.2  Volume.2  \\\n",
       "0  0.315107  0.014362  0.221744  0.221735  0.219592  0.218835  0.071630   \n",
       "1  0.316131  0.005885  0.216649  0.221677  0.222476  0.225798  0.064605   \n",
       "2  0.307302  0.008160  0.217424  0.217205  0.220296  0.218899  0.031678   \n",
       "3  0.307065  0.016842  0.216899  0.217857  0.221881  0.220296  0.035793   \n",
       "4  0.308051  0.003199  0.219603  0.218163  0.222712  0.221599  0.059641   \n",
       "\n",
       "     Open.3    High.3     Low.3   Close.3  Volume.3  \n",
       "0  0.121008  0.120398  0.120547  0.121613  0.265755  \n",
       "1  0.119878  0.121420  0.124930  0.127285  0.215039  \n",
       "2  0.124445  0.119637  0.127240  0.125837  0.218488  \n",
       "3  0.124038  0.120821  0.128372  0.126066  0.164931  \n",
       "4  0.124868  0.122011  0.128281  0.127560  0.189904  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Read In Data \n",
    "\n",
    "data = pd.read_csv('CleanData.csv') \n",
    "data.head()\n",
    "y = data[\"Open\"]\n",
    "X = data.drop(['Open'], axis=1)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2832, 19)\n",
      "(1897, 1, 19)\n"
     ]
    }
   ],
   "source": [
    "#Shift data to predict on next day\n",
    "y = y.drop(y.index[0])\n",
    "X = X.drop(X.index[len(X)-1])\n",
    "print(X.shape)\n",
    "#Train Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .33, random_state = 1234)\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)\n",
    "\n",
    "X_train = np.reshape(X_train, [X_train.shape[0], 1, X_train.shape[1]])\n",
    "X_test = np.reshape(X_test, [X_test.shape[0], 1,  X_test.shape[1]])\n",
    "print(X_train.shape)\n",
    "\n",
    "#TODO \n",
    "#Validation Set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      " - 4s - loss: 0.0032\n",
      "Epoch 2/100\n",
      " - 3s - loss: 1.9471e-04\n",
      "Epoch 3/100\n",
      " - 3s - loss: 1.6135e-04\n",
      "Epoch 4/100\n",
      " - 4s - loss: 1.3848e-04\n",
      "Epoch 5/100\n",
      " - 4s - loss: 1.3378e-04\n",
      "Epoch 6/100\n",
      " - 4s - loss: 1.1716e-04\n",
      "Epoch 7/100\n",
      " - 4s - loss: 9.7332e-05\n",
      "Epoch 8/100\n",
      " - 3s - loss: 8.9819e-05\n",
      "Epoch 9/100\n",
      " - 3s - loss: 9.3237e-05\n",
      "Epoch 10/100\n",
      " - 4s - loss: 7.5918e-05\n",
      "Epoch 11/100\n",
      " - 4s - loss: 7.4625e-05\n",
      "Epoch 12/100\n",
      " - 4s - loss: 8.6189e-05\n",
      "Epoch 13/100\n",
      " - 3s - loss: 6.7792e-05\n",
      "Epoch 14/100\n",
      " - 3s - loss: 6.6766e-05\n",
      "Epoch 15/100\n",
      " - 3s - loss: 6.6149e-05\n",
      "Epoch 16/100\n",
      " - 3s - loss: 6.8173e-05\n",
      "Epoch 17/100\n",
      " - 3s - loss: 7.3509e-05\n",
      "Epoch 18/100\n",
      " - 4s - loss: 6.4518e-05\n",
      "Epoch 19/100\n",
      " - 4s - loss: 6.2023e-05\n",
      "Epoch 20/100\n",
      " - 4s - loss: 6.1792e-05\n",
      "Epoch 21/100\n",
      " - 3s - loss: 5.9469e-05\n",
      "Epoch 22/100\n",
      " - 3s - loss: 5.8426e-05\n",
      "Epoch 23/100\n",
      " - 3s - loss: 5.8559e-05\n",
      "Epoch 24/100\n",
      " - 3s - loss: 7.5152e-05\n",
      "Epoch 25/100\n",
      " - 5s - loss: 5.2766e-05\n",
      "Epoch 26/100\n",
      " - 3s - loss: 5.5191e-05\n",
      "Epoch 27/100\n",
      " - 4s - loss: 5.9775e-05\n",
      "Epoch 28/100\n",
      " - 3s - loss: 5.1911e-05\n",
      "Epoch 29/100\n",
      " - 4s - loss: 5.2764e-05\n",
      "Epoch 30/100\n",
      " - 3s - loss: 5.2217e-05\n",
      "Epoch 31/100\n",
      " - 3s - loss: 6.2061e-05\n",
      "Epoch 32/100\n",
      " - 3s - loss: 5.1940e-05\n",
      "Epoch 33/100\n",
      " - 3s - loss: 5.7962e-05\n",
      "Epoch 34/100\n",
      " - 4s - loss: 5.1481e-05\n",
      "Epoch 35/100\n",
      " - 4s - loss: 5.2045e-05\n",
      "Epoch 36/100\n",
      " - 4s - loss: 5.2791e-05\n",
      "Epoch 37/100\n",
      " - 4s - loss: 6.8825e-05\n",
      "Epoch 38/100\n",
      " - 3s - loss: 5.4448e-05\n",
      "Epoch 39/100\n",
      " - 3s - loss: 5.1081e-05\n",
      "Epoch 40/100\n",
      " - 4s - loss: 5.0964e-05\n",
      "Epoch 41/100\n",
      " - 4s - loss: 5.1994e-05\n",
      "Epoch 42/100\n",
      " - 4s - loss: 4.7618e-05\n",
      "Epoch 43/100\n",
      " - 3s - loss: 4.6145e-05\n",
      "Epoch 44/100\n",
      " - 3s - loss: 5.2648e-05\n",
      "Epoch 45/100\n",
      " - 3s - loss: 4.9319e-05\n",
      "Epoch 46/100\n",
      " - 4s - loss: 5.5869e-05\n",
      "Epoch 47/100\n",
      " - 4s - loss: 4.6168e-05\n",
      "Epoch 48/100\n",
      " - 4s - loss: 5.1207e-05\n",
      "Epoch 49/100\n",
      " - 4s - loss: 4.7454e-05\n",
      "Epoch 50/100\n",
      " - 3s - loss: 4.4122e-05\n",
      "Epoch 51/100\n",
      " - 3s - loss: 4.6072e-05\n",
      "Epoch 52/100\n",
      " - 4s - loss: 4.6070e-05\n",
      "Epoch 53/100\n",
      " - 3s - loss: 5.5937e-05\n",
      "Epoch 54/100\n",
      " - 4s - loss: 4.6646e-05\n",
      "Epoch 55/100\n",
      " - 4s - loss: 4.5855e-05\n",
      "Epoch 56/100\n",
      " - 3s - loss: 4.6862e-05\n",
      "Epoch 57/100\n",
      " - 3s - loss: 4.3231e-05\n",
      "Epoch 58/100\n",
      " - 3s - loss: 4.6880e-05\n",
      "Epoch 59/100\n",
      " - 3s - loss: 4.3798e-05\n",
      "Epoch 60/100\n",
      " - 4s - loss: 4.7848e-05\n",
      "Epoch 61/100\n",
      " - 3s - loss: 4.9421e-05\n",
      "Epoch 62/100\n",
      " - 5s - loss: 4.7367e-05\n",
      "Epoch 63/100\n",
      " - 4s - loss: 4.8127e-05\n",
      "Epoch 64/100\n",
      " - 4s - loss: 4.1311e-05\n",
      "Epoch 65/100\n",
      " - 4s - loss: 4.3929e-05\n",
      "Epoch 66/100\n",
      " - 4s - loss: 4.5080e-05\n",
      "Epoch 67/100\n",
      " - 4s - loss: 4.4642e-05\n",
      "Epoch 68/100\n",
      " - 3s - loss: 4.8756e-05\n",
      "Epoch 69/100\n",
      " - 3s - loss: 4.7599e-05\n",
      "Epoch 70/100\n",
      " - 3s - loss: 4.0038e-05\n",
      "Epoch 71/100\n",
      " - 4s - loss: 4.4674e-05\n",
      "Epoch 72/100\n",
      " - 3s - loss: 4.5951e-05\n",
      "Epoch 73/100\n",
      " - 3s - loss: 4.0287e-05\n",
      "Epoch 74/100\n",
      " - 4s - loss: 4.1927e-05\n",
      "Epoch 75/100\n",
      " - 3s - loss: 4.7294e-05\n",
      "Epoch 76/100\n",
      " - 3s - loss: 4.2593e-05\n",
      "Epoch 77/100\n",
      " - 3s - loss: 4.4372e-05\n",
      "Epoch 78/100\n",
      " - 3s - loss: 4.5314e-05\n",
      "Epoch 79/100\n",
      " - 3s - loss: 4.5386e-05\n",
      "Epoch 80/100\n",
      " - 3s - loss: 3.9302e-05\n",
      "Epoch 81/100\n",
      " - 3s - loss: 4.4354e-05\n",
      "Epoch 82/100\n",
      " - 3s - loss: 4.5661e-05\n",
      "Epoch 83/100\n",
      " - 3s - loss: 4.6892e-05\n",
      "Epoch 84/100\n",
      " - 3s - loss: 4.2379e-05\n",
      "Epoch 85/100\n",
      " - 3s - loss: 4.5449e-05\n",
      "Epoch 86/100\n",
      " - 4s - loss: 4.5823e-05\n",
      "Epoch 87/100\n",
      " - 3s - loss: 4.0515e-05\n",
      "Epoch 88/100\n",
      " - 3s - loss: 3.9121e-05\n",
      "Epoch 89/100\n",
      " - 3s - loss: 4.8121e-05\n",
      "Epoch 90/100\n",
      " - 3s - loss: 4.3130e-05\n",
      "Epoch 91/100\n",
      " - 3s - loss: 4.3290e-05\n",
      "Epoch 92/100\n",
      " - 3s - loss: 4.0287e-05\n",
      "Epoch 93/100\n",
      " - 3s - loss: 4.5302e-05\n",
      "Epoch 94/100\n",
      " - 3s - loss: 4.3195e-05\n",
      "Epoch 95/100\n",
      " - 4s - loss: 4.0150e-05\n",
      "Epoch 96/100\n",
      " - 4s - loss: 4.2924e-05\n",
      "Epoch 97/100\n",
      " - 4s - loss: 4.3184e-05\n",
      "Epoch 98/100\n",
      " - 4s - loss: 3.9020e-05\n",
      "Epoch 99/100\n",
      " - 4s - loss: 4.9427e-05\n",
      "Epoch 100/100\n",
      " - 4s - loss: 3.6577e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7fb08c537a58>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create Model \n",
    "model = Sequential()\n",
    "model.add(LSTM(10, input_shape=(1, 19)))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=1, verbose=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score: 1168.26 RMSE\n",
      "Test Score: 1120.02 RMSE\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "Human_Df = pd.read_csv(\"CleanDataHuman.csv\")\n",
    "Human_Df = Human_Df.drop([\"Ticker\"], axis = 1)\n",
    "\n",
    "unTransformed_data = np.array(Human_Df)[4].reshape(-1, 1)\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "scaler.fit_transform(unTransformed_data )\n",
    "\n",
    "\n",
    "# make predictions\n",
    "trainPredict = model.predict(X_train)\n",
    "testPredict = model.predict(X_test)\n",
    "# invert predictions\n",
    "\n",
    "trainPredict = scaler.inverse_transform(trainPredict)\n",
    "trainY = scaler.inverse_transform([y_train])\n",
    "\n",
    "testPredict = scaler.inverse_transform(testPredict)\n",
    "testY = scaler.inverse_transform([y_test])\n",
    "# calculate root mean squared error\n",
    "trainScore = math.sqrt(mean_squared_error(trainY[0], trainPredict[:,0]))\n",
    "print('Train Score: %.2f RMSE' % (trainScore))\n",
    "testScore = math.sqrt(mean_squared_error(testY[0], testPredict[:,0]))\n",
    "print('Test Score: %.2f RMSE' % (testScore))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
